{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title:Supervising rain&snow or not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    name:\n",
    "        Bingyu Song    A20364641\n",
    "        Xin Liu        A20353208\n",
    "        Zhipeng liu    A20355209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "project Description:\n",
    "    we are trying to use last years weather condition to supervise if some day would rain,sonw or not.\n",
    "    The data we got is about Chicago last 10 years weather from  'https://www.wundrground.com/history/',using some meatheds in scrapy.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We collect the metadata from \"https://www.wunderground.com/\" and download it by scrapy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'scrapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bd9b86679719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'scrapy'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "import scrapy\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"weather\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = ['https://www.wunderground.com/history/airport/KORD/2006/1/1/MonthlyHistory.html']\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.css(\"h2.history-date::text\").extract_first()\n",
    "        filename = '%s.txt' % page\n",
    "        target=response.css(\"div.obs-table-footer a::attr(href)\").extract_first()\n",
    "        target=response.urljoin(target)\n",
    "        result=requests.get(target)\n",
    "        f=open(filename, 'w+')\n",
    "        f.write(result.text)\n",
    "        f.close()\n",
    "        next=response.css(\"div.next-link a::attr(href)\").extract_first()\n",
    "        target=response.css(\"div.obs-table-footer\").extract_first()\n",
    "        if target is not None:\n",
    "            next_page = response.urljoin(next)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2)process data(Considering the convenience, I rename all file name to '20**-*.csv' manually)\n",
    "    **this method will set all new csv files in same table in order to make next step easier, I put all csv table in a new folder named csv_data\n",
    "    **if you want recheck many times ,please remove all old csv file in 'source data' folder\n",
    "    **And because some wrong of websit, import data in 2009 and 2010 is missing, so I delete all files in 2009 and 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def precoess(file_name):\n",
    "    \n",
    "\t#print(file_name)\n",
    "    \n",
    "\tcolumns = [\"Max TemperatureF\",\"Mean TemperatureF\", \"Min TemperatureF\", \"Max Humidity\",\" Mean Humidity\",\" Min Humidity\", \" Mean Sea Level PressureIn\", \" Mean Wind SpeedMPH\", \" CloudCover\", \" Events\"]\n",
    "\n",
    "\tmonth = file_name.split(\".\")[0].split(\"-\")[-1]\n",
    "\n",
    "\tdata = pd.read_csv(file_name)\n",
    "\n",
    "\tm, n = data.shape\n",
    "\n",
    "\tcdt = pd.Series([str(month)] * m)\n",
    "\n",
    "\tnew_d = data[columns]\n",
    "\n",
    "\tnew_d.insert(0, 'CDT', cdt)\n",
    "\n",
    "\tnew_d.to_csv(file_name.split(\".\")[0] + '-out.csv', index=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\t# read files list from folder \"dataset\"\n",
    "\t#path = \"/Users/Songbingyu17/Desktop/dataset\"\n",
    "\t#files = os.listdir(path)\n",
    "#l = []\n",
    "\n",
    "\tdata_path = \"data/source data/\"\n",
    "\n",
    "\tfor filename in os.listdir(r'data/source data')[1:]:\n",
    "\t\t#print(filename)\n",
    "\t\tif filename.startswith(\"20\"):\n",
    "\t\t\t#print(\"Process file %s\" %filename)\n",
    "\t\t\tprecoess(data_path + filename)\n",
    "\n",
    "\t# Done\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tprint(os.getcwd())\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3) filer table, and I merged all table together by terminal language:\n",
    "        \n",
    "        \n",
    "        cat *.csv >merged.csv\n",
    "      \n",
    "      \n",
    "      and I create a new csv file name  'collection.csv ' to store all date filtered by next method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"data/source data/\"\n",
    "\n",
    "def change_lable(kay):\n",
    "    if kay == '' :\n",
    "        return '0'\t\n",
    "    tem = kay.split(\"-\")\n",
    "    if 'Rain' in tem or 'Snow' in tem:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "myfile = csv.writer(open('collection.csv', 'w', newline=''))\n",
    "\n",
    "myfile.writerow(['CDT','Max TemperatureF','Mean TemperatureF', 'Min TemperatureF', 'Max Humidity',' Mean Humidity',' Min Humidity', ' Mean Sea Level PressureIn', ' Mean Wind SpeedMPH', ' CloudCover', ' Events'])\n",
    "\n",
    "with open(data_path+'merged.csv','r') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    for row in f_csv:\n",
    "        if row[0]=='CDT':\n",
    "            continue\n",
    "        else:\n",
    "            row[10]=change_lable(row[10])\n",
    "        if row[7]=='':\n",
    "            continue\n",
    "        else:\n",
    "            myfile.writerow(row[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) load all data into python matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('collection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "\n",
    "def draw_hist(data,feature_name):\n",
    "\tfig = plt.figure()\n",
    "\ty = []\n",
    "\ty.extend(data['0'])\n",
    "\ty.extend(data['1'])\n",
    "\t\n",
    "\tmean = np.mean(y)\n",
    "\tvariance = np.var(y)\n",
    "\n",
    "\tx = []\n",
    "\tx.append(data['0'])\n",
    "\tx.append(data['1'])\n",
    "\tplt.hist(x,stacked = True, rwidth = 10, color = ['b', 'g'], label = ['not snow or rain', 'snow or rain'])\n",
    "\tplt.legend(loc = 2, fontsize = '8')\n",
    "\tplt.ylabel('count')\n",
    "\tplt.xlabel('value')\n",
    "\tfig.suptitle('histogram of %s' % feature_name)\n",
    "\tplt.title('mean is %0.3f, variance is %0.3f' %(mean, variance),fontsize = '10')\n",
    "\tplt.show()\n",
    "\t#plt.savefig(feature_name)\n",
    "\tplt.close(feature_name)\n",
    "\n",
    "\n",
    "def draw_bar_label(array,feature_name):\n",
    "\tplt.figure()\n",
    "\tnum = len(array)\n",
    "\tc = Counter(array)\n",
    "\th = dict(c)\n",
    "\tx_pos = range(len(list(h.items())))\n",
    "\tx_num = [i for i in h.keys()]\n",
    "\tplt.xticks(x_pos,x_num)\n",
    "\tplt.bar(x_pos, [value/num for value in h.values()],align='center', alpha=0.4)\n",
    "\tplt.xlabel('%s (0 represent not snow or rain, 1 represent snow or rain)' %feature_name)\n",
    "\tplt.ylabel('frequency')\n",
    "\tplt.title(feature_name)\n",
    "\t#plt.savefig(feature_name)\n",
    "\tplt.show()\n",
    "\tplt.close()\n",
    "\n",
    "def draw_bar(data,feature_name):\n",
    "\tfig = plt.figure()\n",
    "\tfig.suptitle('bar plot of %s' % feature_name)\n",
    "\n",
    "\tc0 = Counter(data['0'])\n",
    "\th0 = dict(c0)\n",
    "\tc1 = Counter(data['1'])\n",
    "\th1 = dict(c1)\n",
    "\n",
    "    #let h0& h1 have the same length\n",
    "\tfor k in h0:\n",
    "\t\tif not k in h1:\n",
    "\t\t\th1[k] = 0\n",
    "\tfor kk in h1:\n",
    "\t\tif not kk in h0:\n",
    "\t\t\th0[k] = 1\n",
    "\t\n",
    "\tx_pos = range(len(list(h0.items())))\n",
    "\tx_num = [i for i in h0.keys()]\n",
    "\tplt.xticks(x_pos,x_num)\n",
    "\tp1 = plt.bar(x_pos, h0.values(),align='center', alpha=0.4,color = 'b')\n",
    "\tp2 = plt.bar(x_pos, h1.values(),align = 'center',alpha = 0.4, bottom = h0.values(),color = 'g')\n",
    "\tplt.ylabel('count')\n",
    "\tif feature_name == 'CDT':\n",
    "\t\tplt.legend((p1[0],p2[0]), ('not snow or rain', 'snow or rain'),fontsize = '8')\n",
    "\t\tplt.xlabel('month')\n",
    "\tif feature_name == ' CloudCover':\n",
    "\t\tplt.legend((p1[0],p2[0]), ('not snow or rain', 'snow or rain'),loc = 2,fontsize = '8')\n",
    "\t\tplt.xlabel('degree of cloud cover')\n",
    "\t#plt.savefig(feature_name)\n",
    "\tplt.show()\n",
    "\tplt.close()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\t#load data\n",
    "\tfile_object = open(\"collection.csv\")\n",
    "\tfile = []\n",
    "\tfor lines in file_object:\n",
    "\t\tfile.append(lines.strip('\\n'))\n",
    "\tfile_object.close()\n",
    "\n",
    "\t#get feature names\n",
    "\tnames = file[0]\n",
    "\tname_list = names.split(',')\n",
    "\n",
    "\t#get each features data, stores in data[](list of dict)\n",
    "\t#store the result of labels in label[](just a list)\n",
    "\tdata=[]\n",
    "\tlabel = []\n",
    "\tfor j in range(0,10):\n",
    "\t\tdata.append({'0':[], '1':[]})\n",
    "\tfor i in range(1,len(file)):\n",
    "\t\tstrings = file[i].split(',')\n",
    "\t\tlabel.append(int(strings[10]))\n",
    "\t\tfor index in range(0,10):\n",
    "\t\t\tif strings[10] == '0':\n",
    "\t\t\t\tdata[index]['0'].append(float(strings[index]))\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata[index]['1'].append(float(strings[index]))\n",
    "\n",
    "\tbar_list = [0,9,10]\n",
    "\n",
    "\tfor n in range(0,len(name_list)):\n",
    "\t\tif n in bar_list:\n",
    "\t\t\tif n == 10:\n",
    "\t\t\t\tdraw_bar_label(label, name_list[n])\n",
    "\t\t\telse:\n",
    "\t\t\t\tdic = data[n]\n",
    "\t\t\t\tdraw_bar(dic,name_list[n])\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tfeature_name = name_list[n]\n",
    "\t\t\tdic = data[n]\n",
    "\t\t\tdraw_hist(dic,feature_name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
