{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Supervising rain & snow or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Group Members:\n",
    "        Bingyu Song    A20364641\n",
    "        Xin Liu        A20353208\n",
    "        Zhipeng liu    A20355209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Project Description:\n",
    "    This project aims to supervise whether one day would rain or snow, according to this day's weather conditon. The data we used is last ten years weather information of Chicago collect from ”https://www.wundrground.com/history/“. We use some methods from scrapy library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.Load Data \n",
    "In the following part, we load the data that is already processed in the last phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "label=[]\n",
    "\n",
    "f=open('collection','r')\n",
    "content=f.read()\n",
    "content=content.split('\\n')\n",
    "for i in range(0,len(content)-1):\n",
    "\tline=content[i].split(',')\n",
    "\tline = [float(j) for j in line]\n",
    "\tdata.append(line[1:-1])\n",
    "\tlabel.append(line[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Scale data and print the data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instance:  2982\n",
      "number of features:  9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "data = scale(data,copy = 'False')\n",
    "print(\"number of instance: \", len(data))\n",
    "print(\"number of features: \", len(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Choose a performance measure\n",
    "    This is a classification tasks, and there are two results: rain or snow and not rain or snow. The weight of these two result is the same. Thus we choose accuracy as performance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Performance of baselines.\n",
    "    Since this is a classification tasks, we use performance of random prediction and performance of predicting the majority class all the time as the baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of predicting the majority class all the time:  0.5392354124748491\n",
      "accuracy of random prediction: 0.5134138162307177\n"
     ]
    }
   ],
   "source": [
    "cout = 0;\n",
    "for i in label:\n",
    "\tif(i == 0):\n",
    "\t\tcout = cout + 1\n",
    "print(\"accuracy of predicting the majority class all the time: \",cout/2982)\n",
    "\n",
    "import random\n",
    "cout = 0;\n",
    "for i in label:\n",
    "\tif(i == random.randint(0,1)):\n",
    "\t\tcout = cout + 1\n",
    "print(\"accuracy of random prediction:\", cout/2982)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. Model Selection    \n",
    "We use two models, decision tree and logistic regression, to train the data. For each model we performed different parameter settings. Then we calculated the accuracy of each situation, and chose the model and parameter setting which has the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following show the performance of decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 entropy:\n",
      "0.712610081723\n",
      "max_depth =  5 min weight frac =  0.1 accu :  0.75888195929\n",
      "max_depth =  5 min weight frac =  0.15 accu :  0.746463501482\n",
      "max_depth =  5 min weight frac =  0.2 accu :  0.743443367254\n",
      "max_depth =  5 min weight frac =  0.3 accu :  0.755210931035\n",
      "max_depth =  10 min weight frac =  0.1 accu :  0.75888195929\n",
      "max_depth =  10 min weight frac =  0.15 accu :  0.746463501482\n",
      "max_depth =  10 min weight frac =  0.2 accu :  0.743443367254\n",
      "max_depth =  10 min weight frac =  0.3 accu :  0.755210931035\n",
      "max_depth =  20 min weight frac =  0.1 accu :  0.75888195929\n",
      "max_depth =  20 min weight frac =  0.15 accu :  0.746463501482\n",
      "max_depth =  20 min weight frac =  0.2 accu :  0.743443367254\n",
      "max_depth =  20 min weight frac =  0.3 accu :  0.755210931035\n",
      "2 gini:\n",
      "0.712610081723\n",
      "max_depth =  5 min weight frac =  0.1 accu :  0.770963694089\n",
      "max_depth =  5 min weight frac =  0.15 accu :  0.758567788273\n",
      "max_depth =  5 min weight frac =  0.2 accu :  0.758567788273\n",
      "max_depth =  5 min weight frac =  0.3 accu :  0.758567788273\n",
      "max_depth =  10 min weight frac =  0.1 accu :  0.770963694089\n",
      "max_depth =  10 min weight frac =  0.15 accu :  0.758567788273\n",
      "max_depth =  10 min weight frac =  0.2 accu :  0.758567788273\n",
      "max_depth =  10 min weight frac =  0.3 accu :  0.758567788273\n",
      "max_depth =  20 min weight frac =  0.1 accu :  0.770963694089\n",
      "max_depth =  20 min weight frac =  0.15 accu :  0.758567788273\n",
      "max_depth =  20 min weight frac =  0.2 accu :  0.758567788273\n",
      "max_depth =  20 min weight frac =  0.3 accu :  0.758567788273\n"
     ]
    }
   ],
   "source": [
    "def entro(x,y):\n",
    "\tclf = tree.DecisionTreeClassifier(random_state = 0, criterion = \"entropy\",max_depth = x,min_weight_fraction_leaf = y) \n",
    "\tclf = clf.fit(data,label)\n",
    "\tout = cross_val_score(clf,data,label,cv = 10,scoring = \"accuracy\")\n",
    "\tprint(\"max_depth = \",x,\"min weight frac = \",y,\"accu : \",out.mean())\n",
    "def gini(x,y):\n",
    "\tclf = tree.DecisionTreeClassifier(random_state = 0, criterion = \"gini\",max_depth = x,min_weight_fraction_leaf = y) \n",
    "\tclf = clf.fit(data,label)\n",
    "\tout = cross_val_score(clf,data,label,cv = 10,scoring = \"accuracy\")\n",
    "\tprint(\"max_depth = \",x,\"min weight frac = \",y,\"accu : \",out.mean())\n",
    "\n",
    "print(\"1 entropy:\")\n",
    "clf = tree.DecisionTreeClassifier(random_state = 0, criterion = \"entropy\") \n",
    "clf = clf.fit(data,label)\n",
    "out = cross_val_score(clf,data,label,cv = 10,scoring = \"accuracy\")\n",
    "print(out.mean())\n",
    "list1 = [5,10,20]\n",
    "list2 = [0.1,0.15,0.2,0.3]\n",
    "for i in list1:\n",
    "\tfor j in list2:\n",
    "\t\tentro(i,j)\n",
    "print(\"2 gini:\")\n",
    "clf = tree.DecisionTreeClassifier(random_state = 0, criterion = \"entropy\") \n",
    "clf = clf.fit(data,label)\n",
    "out = cross_val_score(clf,data,label,cv = 10,scoring = \"accuracy\")\n",
    "print(out.mean())\n",
    "for i in list1:\n",
    "\tfor j in list2:\n",
    "\t\tgini(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Following shows the performace of logistic regression.\n",
    "    (Because in LogisticRegression when the penalty is L1, the solver only can be liblinear, we dericatly set it as 'liblinear')\n",
    "    expline important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 default:\n",
      "0.786384268716\n",
      "other combine:\n",
      "solver =  newton-cg   fit intercept =  0    accu =  0.782025219536\n",
      "solver =  newton-cg   fit intercept =  1    accu =  0.786384268716\n",
      "solver =  lbfgs   fit intercept =  0    accu =  0.782025219536\n",
      "solver =  lbfgs   fit intercept =  1    accu =  0.786384268716\n",
      "solver =  liblinear   fit intercept =  0    accu =  0.781689649066\n",
      "solver =  liblinear   fit intercept =  1    accu =  0.786384268716\n",
      "solver =  sag   fit intercept =  0    accu =  0.781689649066\n",
      "solver =  sag   fit intercept =  1    accu =  0.786384268716\n",
      "l1 default:\n",
      "0.785715372395\n",
      "other combine:\n",
      "fit intercept =  0    accu =  0.78202296736\n",
      "fit intercept =  1    accu =  0.785715372395\n"
     ]
    }
   ],
   "source": [
    "def l2(x,y):\n",
    "\tclf = LogisticRegression(penalty = 'l2',random_state = 0, solver = x, fit_intercept = y)\n",
    "\tclf = clf.fit(data,label)\n",
    "\tout = cross_val_score(clf,data,label,cv = 10,scoring = \"accuracy\")\n",
    "\tprint(\"solver = \",x,\"  fit intercept = \",y,\"   accu = \",out.mean())\n",
    "def l1(x):\n",
    "\tclf = LogisticRegression(penalty = 'l1',random_state = 0, solver = \"liblinear\", fit_intercept = x)\n",
    "\tclf = clf.fit(data,label)\n",
    "\tout = cross_val_score(clf,data,label,cv = 10,scoring = \"accuracy\")\n",
    "\tprint(\"fit intercept = \",x,\"   accu = \",out.mean())\n",
    "\n",
    "list1 = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\"]\n",
    "list2 = [0,1]\n",
    "print(\"l2 default:\")\n",
    "clf = LogisticRegression(penalty = 'l2',random_state = 0)\n",
    "clf = clf.fit(data,label)\n",
    "out = cross_val_score(clf,data,label,cv = 10,scoring = \"accuracy\")\n",
    "print(out.mean())\n",
    "print (\"other combine:\")\n",
    "for i in list1:\n",
    "\tfor j in list2:\n",
    "\t\tl2(i,j)\n",
    "\n",
    "list3 = [0,1]\n",
    "print(\"l1 default:\")\n",
    "clf = LogisticRegression(penalty = 'l1',random_state = 0)\n",
    "clf = clf.fit(data,label)\n",
    "out = cross_val_score(clf,data,label,cv = 10,scoring = \"accuracy\")\n",
    "print(out.mean())\n",
    "print (\"other combine:\")\n",
    "for i in list3:\n",
    "\tl1(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    According to the largest accuracy of decision tree model is smaller than the accurancy of logistoc regression,so we finally choose the logistic regression as the trainning model. And the settings is: random state = 0, use L2 penalty. The accuracy of choosen model is 0.786384268716."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### 6. Important features\n",
    "Since we choose the logistic regression as the model, we should print the top features and their weights. The result is as following. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our datasets, the top positive feature is cloud cover, the top negative features is min humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight of every feature in model with best accu:  [-0.02481411 -0.03967761 -0.11564139  0.31405758  0.67122156 -0.56750533\n",
      " -0.27897368  0.34060044  1.55704777]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty = 'l2',random_state = 0)\n",
    "clf = clf.fit(data,label)\n",
    "print(\"weight of every feature in model with best accu: \",clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
